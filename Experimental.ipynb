{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experimental.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yakuy/Gemastik13/blob/master/Experimental.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxvAY8FxiuhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b85de81d-e1f5-4688-9542-d68e5ad80480"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV98smqncCZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "d92dd1bc-edeb-43bc-cb7b-9d5edc35e3b3"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 3117733956546921474, name: \"/device:XLA_CPU:0\"\n",
              " device_type: \"XLA_CPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 2292411844217631528\n",
              " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
              " device_type: \"XLA_GPU\"\n",
              " memory_limit: 17179869184\n",
              " locality {\n",
              " }\n",
              " incarnation: 8255140984114228053\n",
              " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14640891840\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 5443547734947874108\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoyTcdTHSanQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip3 install torch==0.3.1 torchvision==0.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VHAqaCbiw4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9bb29238-ade6-4267-b028-beb4903a3afa"
      },
      "source": [
        "#capsnet\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "#chexnet\n",
        "import sys\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from collections import OrderedDict\n",
        "#train network\n",
        "import os\n",
        "import datetime\n",
        "import json\n",
        "import glob\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch import optim\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix, roc_curve, auc, f1_score\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "from scipy import interp\n",
        "from itertools import cycle\n",
        "from tqdm import tqdm\n",
        "#load data\n",
        "from torch.utils.data import Dataset\n",
        "import random\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leDUsCrRMfwH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#buat load data\n",
        "class ChestXrayDataSetTest(Dataset):\n",
        "    def __init__(self, image_list_file, transform=None, combine_pneumonia=False):\n",
        "        \"\"\"\n",
        "        Create the Data Loader.\n",
        "        Since class 3 (Covid) has limited data, dataset size will be accordingly at train time.\n",
        "        Code is written in generic form to assume last class as the rare class\n",
        "\n",
        "        Args:\n",
        "            image_list_file: path to the file containing images\n",
        "                with corresponding labels.\n",
        "            transform: optional transform to be applied on a sample.\n",
        "            combine_pneumonia: True for combining Baterial and Viral Pneumonias into one class\n",
        "        \"\"\"\n",
        "        self.NUM_CLASSES = 3 if combine_pneumonia else 4\n",
        "\n",
        "        # Set of images for each class\n",
        "        image_names = []\n",
        "\n",
        "        with open(image_list_file, \"r\") as f:\n",
        "            for line in f:\n",
        "                items = line.split()\n",
        "                image_name = items[0]+' '+items[1]\n",
        "                label = int(items[2])\n",
        "                image_names.append((image_name, label))\n",
        "\n",
        "        self.image_names = image_names\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index: the index of item\n",
        "\n",
        "        Returns:\n",
        "            image and its labels\n",
        "        \"\"\"\n",
        "        def __one_hot_encode(l):\n",
        "            v = [0] * self.NUM_CLASSES\n",
        "            v[l] = 1\n",
        "            return v\n",
        "\n",
        "        image_name, label = self.image_names[index]\n",
        "        label = __one_hot_encode(label)\n",
        "\n",
        "        image = Image.open(image_name).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.FloatTensor(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_names)\n",
        "\n",
        "\n",
        "class ChestXrayDataSet(Dataset):\n",
        "    def __init__(self, image_list_file, transform=None, combine_pneumonia=False):\n",
        "        \"\"\"\n",
        "        Create the Data Loader.\n",
        "        Since class 3 (Covid) has limited data, dataset size will be accordingly at train time.\n",
        "        Code is written in generic form to assume last class as the rare class\n",
        "\n",
        "        Args:\n",
        "            image_list_file: path to the file containing images\n",
        "                with corresponding labels.\n",
        "            transform: optional transform to be applied on a sample.\n",
        "            combine_pneumonia: True for combining Baterial and Viral Pneumonias into one class\n",
        "        \"\"\"\n",
        "        self.NUM_CLASSES = 3 if combine_pneumonia else 4\n",
        "\n",
        "        # Set of images for each class\n",
        "        image_names = [[] for _ in range(self.NUM_CLASSES)]\n",
        "\n",
        "        with open(image_list_file, \"r\") as f:\n",
        "            for line in f:\n",
        "                items = line.split()\n",
        "                image_name = items[0]+ ' ' + items[1]\n",
        "                label = int(items[2])\n",
        "                image_names[label].append(image_name)\n",
        "\n",
        "        self.image_names = image_names\n",
        "        self.transform = transform\n",
        "\n",
        "        label_dist = [len(cnames) for cnames in image_names]\n",
        "\n",
        "        # Number of images of each class desired\n",
        "        self.num_covid = int(label_dist[-1])\n",
        "\n",
        "        if combine_pneumonia:\n",
        "            covid_factor = 7.0\n",
        "            self.num_normal = int(self.num_covid * covid_factor)\n",
        "            self.num_pneumonia = int(self.num_covid * covid_factor)\n",
        "            self.total = self.num_covid + self.num_pneumonia + self.num_normal\n",
        "            self.loss_weight_minus = torch.FloatTensor([self.num_normal, self.num_pneumonia, self.num_covid]).unsqueeze(0).cuda() / self.total\n",
        "            self.loss_weight_plus = 1.0 - self.loss_weight_minus\n",
        "        else:\n",
        "            covid_factor = 5.0\n",
        "            self.num_normal = int(self.num_covid * covid_factor)\n",
        "            self.num_viral = int(self.num_covid * covid_factor)\n",
        "            self.num_bact = int(self.num_covid * covid_factor)\n",
        "            self.total = self.num_covid + self.num_viral + self.num_bact + self.num_normal\n",
        "            self.loss_weight_minus = torch.FloatTensor([self.num_normal, self.num_bact, self.num_viral, self.num_covid]).unsqueeze(0).cuda() / self.total\n",
        "            self.loss_weight_plus = 1.0 - self.loss_weight_minus\n",
        "\n",
        "        # print (self.loss_weight_plus, self.loss_weight_minus)\n",
        "\n",
        "        if combine_pneumonia:\n",
        "            self.partitions = [self.num_covid,\n",
        "                                self.num_covid + self.num_normal,\n",
        "                                self.num_covid + self.num_normal + self.num_pneumonia]\n",
        "        else:\n",
        "            self.partitions = [self.num_covid,\n",
        "                                self.num_covid + self.num_normal,\n",
        "                                self.num_covid + self.num_normal + self.num_bact,\n",
        "                                self.num_covid + self.num_normal + self.num_bact + self.num_viral]\n",
        "\n",
        "        assert len(self.partitions) == self.NUM_CLASSES\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            index: the index of item\n",
        "\n",
        "        Returns:\n",
        "            image and its labels\n",
        "        \"\"\"\n",
        "\n",
        "        def __one_hot_encode(l):\n",
        "            v = [0] * self.NUM_CLASSES\n",
        "            v[l] = 1\n",
        "            return v\n",
        "\n",
        "        image_name = None\n",
        "        # print (index, self.partitions, len(self), sum([len(cnames) for cnames in self.image_names]))\n",
        "        if index < self.partitions[0]:\n",
        "            # Return a covid image\n",
        "            data_idx = index\n",
        "            image_name = self.image_names[self.NUM_CLASSES - 1][data_idx]\n",
        "            label = __one_hot_encode(self.NUM_CLASSES - 1)\n",
        "        else:\n",
        "            # Return non-covid image\n",
        "            for l in range(1, self.NUM_CLASSES):\n",
        "                if index < self.partitions[l]:\n",
        "                    class_idx = l - 1\n",
        "                    label = __one_hot_encode(class_idx)\n",
        "                    # Return a random image\n",
        "                    image_name = random.choice(self.image_names[class_idx])\n",
        "                    break\n",
        "\n",
        "        assert image_name is not None\n",
        "        #print(image_name)\n",
        "        image = Image.open(image_name).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.FloatTensor(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.partitions[-1]\n",
        "\n",
        "    def loss(self, output, target):\n",
        "        \"\"\"\n",
        "        Binary weighted cross-entropy loss for each class\n",
        "        \"\"\"\n",
        "        weight_plus = torch.autograd.Variable(self.loss_weight_plus.repeat(1, target.size(0)).view(-1, self.loss_weight_plus.size(1)).cuda())\n",
        "        weight_neg = torch.autograd.Variable(self.loss_weight_minus.repeat(1, target.size(0)).view(-1, self.loss_weight_minus.size(1)).cuda())\n",
        "\n",
        "        loss = output\n",
        "        pmask = (target >= 0.5).data\n",
        "        nmask = (target < 0.5).data\n",
        "        \n",
        "        epsilon = 1e-15\n",
        "        loss[pmask] = (loss[pmask] + epsilon).log() * weight_plus[pmask]\n",
        "        loss[nmask] = (1-loss[nmask] + epsilon).log() * weight_plus[nmask]\n",
        "        loss = -loss.sum()\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnrIXcc08pK9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_IMAGE_LIST = '/content/drive/My Drive/CovidAID/data/new_train.txt'\n",
        "VAL_IMAGE_LIST = '/content/drive/My Drive/CovidAID/data/new_val.txt'\n",
        "TEST_IMAGE_LIST = '/content/drive/My Drive/CovidAID/data/new_test.txt'\n",
        "TEST_DIR = '/content/drive/My Drive/CovidAID/data/samples'\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}